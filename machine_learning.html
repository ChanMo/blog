<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2023-03-25 六 14:25 -->
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Machine Learning</title>
<meta name="author" content="ChanMo" />
<meta name="description" content="Machine Learning Cookbook" />
<meta name="keywords" content="ml, ai, pytorch, nlp" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css'><link rel='stylesheet' href='app.css'>
<script async src='https://www.googletagmanager.com/gtag/js?id=G-XFRJ9KBERX'></script><script>window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('config', 'G-XFRJ9KBERX');</script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=""> UP </a>
 |
 <a accesskey="H" href="/blog"> HOME </a>
</div><div id="content" class="content">
<h1 class="title">Machine Learning</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org18c1290">1. Basic Packages</a>
<ul>
<li><a href="#org362cd7c">1.1. Numpy</a></li>
<li><a href="#org43f818d">1.2. Matplotlib</a></li>
</ul>
</li>
<li><a href="#orgb6f5946">2. AI Packages</a>
<ul>
<li><a href="#org82b4066">2.1. Pytorch</a></li>
<li><a href="#orgb81febb">2.2. Fastai</a></li>
<li><a href="#org8c6f9a6">2.3. Transformers</a></li>
</ul>
</li>
<li><a href="#orgd1c392f">3. AI Products</a>
<ul>
<li><a href="#org53332d2">3.1. Stable Diffusion</a></li>
<li><a href="#org43c408b">3.2. Whisper</a></li>
</ul>
</li>
<li><a href="#org4a00c9c">4. Modules</a></li>
<li><a href="#org40d352d">5. Deep Learning</a>
<ul>
<li><a href="#org3b843a2">5.1. Convolutional Neural Network, CNN</a></li>
<li><a href="#org807a2f4">5.2. U-Net</a></li>
<li><a href="#org44751c2">5.3. Residual neural network (残差神经网络, ResNet)</a></li>
<li><a href="#org265362e">5.4. Generative Adversarial Network (生成对抗网络, GAN)</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org18c1290" class="outline-2">
<h2 id="org18c1290"><span class="section-number-2">1.</span> Basic Packages</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org362cd7c" class="outline-3">
<h3 id="org362cd7c"><span class="section-number-3">1.1.</span> Numpy</h3>
<div class="outline-text-3" id="text-1-1">
<p>
NumPy是Python语言的一个扩展程序库。支持高阶大规模的多维数组与矩阵运算，
此外也针对数组运算提供大量的数学函数库。
NumPy的前身Numeric最早是由Jim Hugunin与其它协作者共同开发，
2005年，Travis Oliphant在Numeric中结合了另一个同性质的程序库Numarray的特色，
并加入了其它扩展而开发了NumPy。
NumPy为开放源代码并且由许多协作者共同维护开发。
</p>

<p>
<a href="https://zh.wikipedia.org/wiki/NumPy">wikipedia</a>
</p>
</div>
</div>

<div id="outline-container-org43f818d" class="outline-3">
<h3 id="org43f818d"><span class="section-number-3">1.2.</span> Matplotlib</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Matplotlib是Python语言及其数值计算库NumPy的绘图库。
它提供了一个面向对象的API，可以将绘图嵌入到使用通用GUI工具包
（如Tkinter、wxPython、Qt或GTK）的程序中。
它还有一个基于状态机（如OpenGL）的过程式编程“pylab”接口，其设计与MATLAB非常类似，
但由于命名空间的问题，因此建议改用matplotlib.pyplot取代。
</p>

<p>
<a href="https://zh.wikipedia.org/zh-cn/Matplotlib">wikipedia</a>
</p>
</div>
</div>
</div>


<div id="outline-container-orgb6f5946" class="outline-2">
<h2 id="orgb6f5946"><span class="section-number-2">2.</span> AI Packages</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org82b4066" class="outline-3">
<h3 id="org82b4066"><span class="section-number-3">2.1.</span> Pytorch</h3>
<div class="outline-text-3" id="text-2-1">
<p>
PyTorch是一个开源的Python机器学习库，基于Torch，底层由C++实现，应用于人工智能领域，
如计算机视觉和自然语言处理。它主要由Meta Platforms的人工智能研究团队开发。
著名的用途有：特斯拉自动驾驶，Uber最初发起而现属Linux基金会项目的概率编程软件Pyro，
Lightning。
</p>

<p>
PyTorch主要有两大特征:
</p>

<ul class="org-ul">
<li>类似于NumPy的张量计算，可使用GPU加速；</li>
<li>基于带自动微分系统的深度神经网络。</li>
</ul>

<p>
PyTorch包括torch.autograd、torch.nn、torch.optim等子模块
</p>

<p>
<a href="https://github.com/pytorch/pytorch">github</a>, <a href="https://zh.wikipedia.org/wiki/PyTorch">wikipedia</a>
</p>
</div>
</div>

<div id="outline-container-orgb81febb" class="outline-3">
<h3 id="orgb81febb"><span class="section-number-3">2.2.</span> Fastai</h3>
<div class="outline-text-3" id="text-2-2">
<p>
<a href="https://docs.fast.ai/">https://docs.fast.ai/</a>
</p>
</div>
</div>

<div id="outline-container-org8c6f9a6" class="outline-3">
<h3 id="org8c6f9a6"><span class="section-number-3">2.3.</span> Transformers</h3>
<div class="outline-text-3" id="text-2-3">
<p>
为 Jax、PyTorch 和 TensorFlow 打造的先进的自然语言处理
</p>

<p>
<a href="https://github.com/huggingface/transformers">github</a>
</p>
</div>
</div>
</div>

<div id="outline-container-orgd1c392f" class="outline-2">
<h2 id="orgd1c392f"><span class="section-number-2">3.</span> AI Products</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org53332d2" class="outline-3">
<h3 id="org53332d2"><span class="section-number-3">3.1.</span> Stable Diffusion</h3>
<div class="outline-text-3" id="text-3-1">
<p>
Stable Diffusion是2022年发布的深度学习文本到图像生成模型。
它主要用于根据文本的描述产生详细图像，尽管它也可以应用于其他任务，如内补绘制、外补绘制，
以及在提示词​指导下产生图生图的翻译。
</p>

<p>
它是一种潜在​扩散模型，由慕尼黑大学的CompVis研究团体开发的各种生成性人工神經网络。
它是由初创公司StabilityAI，CompVis与Runway合作开发的，
并得到EleutherAI和LAION​的支持。截至2022年10月，StabilityAI筹集了1.01亿美元的资金。
</p>

<p>
Stable Diffusion的代码和模型权重已公开发布，
可以在大多数配备有适度GPU的电脑硬件上运行。
而以前的专有文生图模型（如DALL-E和Midjourney）只能通过云计算服务访问。
</p>

<p>
<a href="https://github.com/Stability-AI/stablediffusion">github</a>
</p>
</div>
</div>


<div id="outline-container-org43c408b" class="outline-3">
<h3 id="org43c408b"><span class="section-number-3">3.2.</span> Whisper</h3>
<div class="outline-text-3" id="text-3-2">
<p>
By OpenAI
</p>

<p>
Whisper is a general-purpose speech recognition model.
It is trained on a large dataset of diverse audio and is also a multitasking
model that can perform multilingual speech recognition, speech translation,
and language identification.
</p>

<p>
<a href="https://github.com/openai/whisper">github</a>
</p>
</div>
</div>
</div>


<div id="outline-container-org4a00c9c" class="outline-2">
<h2 id="org4a00c9c"><span class="section-number-2">4.</span> Modules</h2>
</div>



<div id="outline-container-org40d352d" class="outline-2">
<h2 id="org40d352d"><span class="section-number-2">5.</span> Deep Learning</h2>
<div class="outline-text-2" id="text-5">
<p>
深度学习（英语：deep learning）是机器学习的分支，是一种以人工神经网络为架构，
对资料进行表征学习的算法。深度学习中的形容词“深度”是指在网络中使用多层。
早期的工作表明，线性感知器不能成为通用分类器，
但具有非多项式激活函数和一个无限宽度隐藏层的网络可以成为通用分类器。
</p>

<p>
深度学习是机器学习中一种基于对数据进行表征学习的算法。
观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的向量，
或者更抽象地表示成一系列边、特定形状的区域等。
而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。
深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。
</p>

<p>
表征学习的目标是寻求更好的表示方法并创建更好的模型来从大规模未标记数据中学习这些表示方法。
表示方法来自神经科学，并松散地创建在类似神经系统中的信息处理和对通信模式的理解上，
如神经编码，试图定义拉动神经元的反应之间的关系以及大脑中的神经元的电活动之间的关系。
</p>

<p>
至今已有数种深度学习框架，如深度神经网络、卷积神经网络和深度置信网络和循环神经网络
已被应用在计算机视觉、语音识别、自然语言处理、音频识别与生物信息学等领域并获取了极好的效果。
</p>

<p>
<a href="https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">wikipedia</a>
</p>
</div>

<div id="outline-container-org3b843a2" class="outline-3">
<h3 id="org3b843a2"><span class="section-number-3">5.1.</span> Convolutional Neural Network, CNN</h3>
<div class="outline-text-3" id="text-5-1">
<p>
卷积神经网络（英语：Convolutional Neural Network，缩写：CNN）是一种前馈神经网络，
它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。
</p>

<p>
卷积神经网络由一个或多个卷积层和顶端的全连通层（对应经典的神经网络）组成，
同时也包括关联权重和池化层（pooling layer）。
这一结构使得卷积神经网络能够利用输入数据的二维结构。与其他深度学习结构相比，
卷积神经网络在图像和语音识别方面能够给出更好的结果。这一模型也可以使用反向传播算法进行训练。
相比较其他深度、前馈神经网络，卷积神经网络需要考量的参数更少，
使之成为一种颇具吸引力的深度学习结构。
</p>

<p>
卷积神经网络的灵感来自于动物视觉皮层组织的神经连接方式。
单个神经元只对有限区域内的刺激作出反应，不同神经元的感知区域相互重叠从而覆盖整个视野。
</p>

<p>
卷积神经网络是人工神经网络的一种特殊类型，
在其至少一层中使用称为卷积的数学运算代替通用矩阵乘法。
它们专门设计用于处理像素数据，并用于图像识别和处理。
</p>

<p>
<a href="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">wikipedia</a>
</p>
</div>
</div>

<div id="outline-container-org807a2f4" class="outline-3">
<h3 id="org807a2f4"><span class="section-number-3">5.2.</span> U-Net</h3>
<div class="outline-text-3" id="text-5-2">
<p>
U-Net是弗赖堡大学计算机科学系为生物医学图像分割开发的卷积神经网络。
其基于完全卷积网络，并在结构上加以修改与扩展，使得它可以用更少的训练图像产生更精确的分割。
在现代GPU上，分割一张512×512的图像需要的时间不到一秒。
</p>
</div>
</div>


<div id="outline-container-org44751c2" class="outline-3">
<h3 id="org44751c2"><span class="section-number-3">5.3.</span> Residual neural network (残差神经网络, ResNet)</h3>
<div class="outline-text-3" id="text-5-3">
<p>
A residual neural network (ResNet) is an artificial neural network (ANN,
人工神经网络). It is a gateless or open-gated variant of the HighwayNet,
the first working very deep feedforward neural network with hundreds of layers,
much deeper than previous neural networks.
Skip connections or shortcuts are used to jump over some layers
(HighwayNets may also learn the skip weights themselves through an
additional weight matrix for their gates). Typical ResNet models are
implemented with double- or triple- layer skips that contain
nonlinearities (ReLU, 修正线性单元) and batch normalization in between.
Models with several parallel skips are referred to as DenseNets.
In the context of residual neural networks,
a non-residual network may be described as a plain network.
</p>

<p>
Like in the case of Long Short-Term Memory recurrent neural networks
there are two main reasons to add skip connections:
to avoid the problem of vanishing gradients, thus leading to easier
optimization of neural networks,
where the gating mechanisms facilitate information flow across many layers
("information highways"), or to mitigate the Degradation (accuracy saturation)
problem; where adding more layers to a suitably deep model leads to
higher training error. During training, the weights adapt to mute the
upstream layer[clarification needed], and amplify the previously-skipped layer.
In the simplest case, only the weights for the adjacent layer's connection
are adapted, with no explicit weights for the upstream layer.
This works best when a single nonlinear layer is stepped over,
or when the intermediate layers are all linear.
If not, then an explicit weight matrix should be learned for the skipped
connection (a HighwayNet should be used).
</p>

<p>
Skipping effectively simplifies the network, using fewer layers in the initial
training stages[clarification needed]. This speeds learning by reducing the
impact of vanishing gradients,[5] as there are fewer layers to propagate
through. The network then gradually restores the skipped layers as it learns
the feature space. Towards the end of training, when all layers are expanded,
it stays closer to the manifold[clarification needed] and thus learns faster.
A neural network without residual parts explores more of the feature space.
This makes it more vulnerable to perturbations that cause it to leave the
manifold, and necessitates extra training data to recover.
</p>

<p>
A residual neural network was used to win the ImageNet 2015 competition,
and has become the most cited neural network of the 21st century.
</p>

<p>
<a href="https://en.wikipedia.org/wiki/Residual_neural_network">wikipedia</a>
</p>
</div>
</div>


<div id="outline-container-org265362e" class="outline-3">
<h3 id="org265362e"><span class="section-number-3">5.4.</span> Generative Adversarial Network (生成对抗网络, GAN)</h3>
<div class="outline-text-3" id="text-5-4">
<p>
生成对抗网络（英语：Generative Adversarial Network，简称GAN）是非监督式学习的一种方法，
透过两个神经网络相互博弈的方式进行学习。该方法由伊恩·古德费洛等人于2014年提出。
生成对抗网络由一个生成网络与一个判别网络组成。生成网络从潜在空间（latent space）
中随机取样作为输入，其输出结果需要尽量模仿训练集中的真实样本。
判别网络的输入则为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能分辨出来。
而生成网络则要尽可能地欺骗判别网络。两个网络相互对抗、不断调整参数，
最终目的是使判别网络无法判断生成网络的输出结果是否真实。
</p>

<p>
生成对抗网络常用于生成以假乱真的图片。此外，该方法还被用于生成视频、三维物体模型等。
</p>

<p>
生成对抗网络虽然最开始提出是为了无监督学习，但经证明对半监督学习、完全监督学习 、
强化学习也有效。
</p>

<p>
生成对抗网络的应用范围正在大幅增加，比如ChatGPT等
</p>

<p>
<a href="https://zh.wikipedia.org/zh-cn/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C">wikipedia</a>
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: ChanMo</p>
<p class="date">Created: 2023-03-25 六 14:25</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>